# ğŸ—£ï¸ Day 11 - Speech-to-Text with Google Speech API vs OpenAI Whisper

This project demonstrates two powerful methods for converting audio to text:

1. **Google Web Speech API**
2. **OpenAI Whisper**

---

## ğŸš€ Project Overview

I explored both **online (Google API)** and **offline (Whisper)** transcription methods to understand their strengths, limitations, and real-world applications.

---

## ğŸ§  Why This Project?

Speech-to-text is being used in:
- Meeting transcription apps (Otter.ai, Fireflies)
- Subtitling and content generation
- Accessibility for the hearing impaired
- Real-time customer service

I wanted to explore both a **quick-to-use API-based approach** and a **deep learning model** for handling longer and noisier audio.

---

## ğŸ”§ Setup Instructions

### âœ… Whisper (Offline)

```bash
pip install -U openai-whisper
sudo apt update && sudo apt install ffmpeg

```

### âœ… Google Speech API (Online)

```bash
pip install SpeechRecognition
pip install PyAudio  # Might need special setup in Colab or Windows
```

## ğŸ’¡ What Each Approach Offers

| Feature              | Google Speech API | OpenAI Whisper |
|----------------------|-------------------|----------------|
| Requires Internet    | âœ… Yes            | âŒ No          |
| Handles Noise        | âš ï¸ Moderate       | âœ… Yes         |
| Long Audio Support   | âŒ No             | âœ… Yes         |
| Multilingual         | âš ï¸ Limited        | âœ… Yes         |
| Open Source          | âŒ No             | âœ… Yes         |
| Speed                | âœ… Fast (live)    | âš ï¸ Slower      |

---

## â— Challenges Faced

| Issue                     | Solution                                         |
|---------------------------|--------------------------------------------------|
| `PyAudio` install errors  | Used Google Colab or pip wheels manually         |
| Whisper model loading slow| Used `small` model to reduce memory usage        |
| Whisper needs `ffmpeg`    | Installed manually on Colab                      |
| Accuracy tradeoffs        | Tested with different samples to compare outputs |

---

## ğŸ“š Reflections & Learnings

- Google API is great for fast, browser-based use cases, especially for real-time transcription.
- OpenAI Whisper is a powerful open-source tool, better suited for offline or longer audio analysis.
- Combining both gives a practical understanding of cloud-based vs edge-based AI systems.
- Whisper's multilingual support opens doors to global accessibility tools.

---

## ğŸ”® Future Additions

- Streamlit UI for both Whisper and Google API  
- Real-time transcription with microphone input  
- Timestamped transcripts for subtitle generation
